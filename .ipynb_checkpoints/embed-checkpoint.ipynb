{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import DataParallel\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "import argparse\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "from functools import partial\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.model import EmbeddingModel\n",
    "from src.dataset import get_dataloader\n",
    "from src.loss import LossBuilder\n",
    "from src.stylegan import G_synthesis, G_mapping\n",
    "from src.spherical_optimizer import SphericalOptimizer\n",
    "from src.utils import open_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = 'data/input_aligned'  \n",
    "output_dir = 'data/output'       \n",
    "cache_dir = 'cache'       \n",
    "batch_size = 1       \n",
    "seed = None       \n",
    "loss_str = '100*L2'       \n",
    "noise_type = 'trainable'       \n",
    "num_trainable_noise_layers = 18       \n",
    "tile_latent = False       \n",
    "bad_noise_layers = '17'         \n",
    "opt_name = 'adam'       \n",
    "learning_rate = 0.4       \n",
    "steps = 500       \n",
    "lr_schedule = 'linear1cycledrop'       \n",
    "save_intermediate = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup output paths\n",
    "out_path = Path(output_dir)\n",
    "out_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load data\n",
    "dataloader = get_dataloader(input_dir, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Synthesis Network\n"
     ]
    }
   ],
   "source": [
    "cache_dir = Path(cache_dir)\n",
    "cache_dir.mkdir(parents=True, exist_ok = True)\n",
    "        \n",
    "# Load StyleGAN\n",
    "synthesis = G_synthesis().cuda()\n",
    "\n",
    "print(\"Loading Synthesis Network\")\n",
    "with open_url(\"https://drive.google.com/uc?id=1TCViX1YpQyRsklTVYEJwdbmK91vklCo8\", cache_dir=cache_dir) as f:\n",
    "            synthesis.load_state_dict(torch.load(f))\n",
    "\n",
    "# Turn off network gradient updates\n",
    "for param in synthesis.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "lrelu = torch.nn.LeakyReLU(negative_slope=0.2)\n",
    "\n",
    "# Load mean + std of mapping network\n",
    "gaussian_fit = torch.load(\"cache/gaussian_fit.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "L2: 0.0000345961: 100%|██████████| 500/500 [01:59<00:00,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST (500) | L2: 0.0000 | TOTAL: 0.0035 | time: 119.3 | it/s: 4.19 | batchsize: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for ref_im, ref_im_name in dataloader:\n",
    "    ref_im = ref_im.cuda()\n",
    "    # Set seed\n",
    "    if seed:\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    batch_size = ref_im.shape[0]\n",
    "\n",
    "    # Generate latent tensor\n",
    "    if tile_latent:\n",
    "        latent = torch.randn((batch_size, 1, 512), dtype=torch.float, \n",
    "                                 requires_grad=True, device='cuda')\n",
    "    else:\n",
    "        latent = torch.randn((batch_size, 18, 512), dtype=torch.float, \n",
    "                                 requires_grad=True, device='cuda')\n",
    "\n",
    "    # Generate list of noise tensors\n",
    "    noise = [] # stores all of the noise tensors\n",
    "    noise_vars = []  # stores the noise tensors that we want to optimize on\n",
    "\n",
    "    for i in range(18):\n",
    "            # dimension of the ith noise tensor\n",
    "        res = (batch_size, 1, 2**(i//2+2), 2**(i//2+2))\n",
    "\n",
    "        if(noise_type == 'zero' or i in [int(layer) for layer in bad_noise_layers.split('.')]):\n",
    "            new_noise = torch.zeros(res, dtype=torch.float, device='cuda')\n",
    "            new_noise.requires_grad = False\n",
    "        elif(noise_type == 'fixed'):\n",
    "            new_noise = torch.randn(res, dtype=torch.float, device='cuda')\n",
    "            new_noise.requires_grad = False\n",
    "        elif (noise_type == 'trainable'):\n",
    "            new_noise = torch.randn(res, dtype=torch.float, device='cuda')\n",
    "            if (i < num_trainable_noise_layers):\n",
    "                new_noise.requires_grad = True\n",
    "                noise_vars.append(new_noise)\n",
    "            else:\n",
    "                new_noise.requires_grad = False\n",
    "        else:\n",
    "            raise Exception(\"unknown noise type\")\n",
    "\n",
    "        noise.append(new_noise)\n",
    "\n",
    "    var_list = [latent]+noise_vars\n",
    "\n",
    "    opt_dict = {\n",
    "            'sgd': torch.optim.SGD,\n",
    "            'adam': torch.optim.Adam,\n",
    "            'sgdm': partial(torch.optim.SGD, momentum=0.9),\n",
    "            'adamax': torch.optim.Adamax\n",
    "    }\n",
    "    opt = SphericalOptimizer(opt_dict[opt_name], var_list, lr=learning_rate)\n",
    "\n",
    "    schedule_dict = {\n",
    "            'fixed': lambda x: 1,\n",
    "            'linear1cycle': lambda x: (9*(1-np.abs(x/steps-1/2)*2)+1)/10,\n",
    "            'linear1cycledrop': lambda x: (9*(1-np.abs(x/(0.9*steps)-1/2)*2)+1)/10 if x < 0.9*steps else 1/10 + (x-0.9*steps)/(0.1*steps)*(1/1000-1/10),\n",
    "    }\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(opt.opt, schedule_dict[lr_schedule])\n",
    "        \n",
    "    loss_builder = LossBuilder(ref_im, loss_str).cuda()\n",
    "\n",
    "    min_loss = np.inf\n",
    "    best_summary = \"\"\n",
    "    start_t = time.time()\n",
    "    gen_im = None\n",
    "\n",
    "    print(\"Optimizing\")\n",
    "    t = tqdm.trange(steps)\n",
    "    for j in t:\n",
    "        opt.opt.zero_grad()\n",
    "\n",
    "        # Duplicate latent in case tile_latent = True\n",
    "        if (tile_latent):\n",
    "            latent_in = latent.expand(-1, 18, -1)\n",
    "        else:\n",
    "            latent_in = latent\n",
    "\n",
    "        # Apply learned linear mapping to match latent distribution to that of the mapping network\n",
    "        latent_in = lrelu(latent_in*gaussian_fit[\"std\"] + gaussian_fit[\"mean\"])\n",
    "\n",
    "        # Normalize image to [0,1] instead of [-1,1]\n",
    "        gen_im = (synthesis(latent_in, noise)+1)/2\n",
    "\n",
    "        # Calculate Losses\n",
    "        loss, loss_dict = loss_builder(latent_in, gen_im)\n",
    "        loss_dict['TOTAL'] = loss\n",
    "\n",
    "        # Save best summary for log\n",
    "        if(loss < min_loss):\n",
    "            min_loss = loss\n",
    "            best_summary = f'BEST ({j+1}) | '+' | '.join(\n",
    "            [f'{x}: {y:.4f}' for x, y in loss_dict.items()])\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        t.set_description('L2: {:.10f}'.format(loss_dict['L2']))\n",
    "\n",
    "    total_t = time.time()-start_t\n",
    "    current_info = f' | time: {total_t:.1f} | it/s: {(j+1)/total_t:.2f} | batchsize: {batch_size}'\n",
    "    print(best_summary+current_info)\n",
    "        \n",
    "    #ield gen_im.clone().cpu().detach().clamp(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "toPIL = torchvision.transforms.ToPILImage()\n",
    "img = toPIL(gen_im.clone().squeeze(0).cpu().detach().clamp(0, 1))\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate new noise\n",
    "re_noise = []\n",
    "for i in range(18):\n",
    "    # dimension of the ith noise tensor\n",
    "    if i < 30:\n",
    "        res = (batch_size, 1, 2**(i//2+2), 2**(i//2+2))\n",
    "\n",
    "        new_noise = torch.randn(res, dtype=torch.float, device='cuda')\n",
    "        new_noise.requires_grad = False\n",
    "        re_noise.append(new_noise)\n",
    "    else:\n",
    "        re_noise.append(noise[i])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_im = (synthesis(latent_in, re_noise)+1)/2\n",
    "img = toPIL(new_im.clone().squeeze(0).cpu().detach().clamp(0, 1))\n",
    "img.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
